{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e71c6e7a",
   "metadata": {},
   "source": [
    "# XGBoost Notebook\n",
    "\n",
    "In this notebook I will train an XGBoost model end to end."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a192b6",
   "metadata": {},
   "source": [
    "### Description\n",
    "\n",
    "This is the April 2025 podcast listening time podcast prediction competition.\n",
    "\n",
    "The goal is to analyze and predict the average listening duration of podcast episodes based on various features.\n",
    "\n",
    "### Files\n",
    "1. train.csv\n",
    "2. test.csv\n",
    "3. sample_submission.csv\n",
    "\n",
    "### Evaluation\n",
    "\n",
    "The evaluation metric is the RMSE.\n",
    "\n",
    "Submission File\n",
    "For each id in the test set, you must predict the number of minutes listened. The file should contain a header and have the following format:\n",
    "\n",
    "- id,Listening_Time_minutes\n",
    "- 26570,0.2\n",
    "- 26571,0.1\n",
    "- 26572,0.9\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccae698",
   "metadata": {},
   "source": [
    "## Package Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314a528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general python libraries\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# dataframe and data manipulation library\n",
    "import pandas as pd\n",
    "\n",
    "# visualisation and EDA libraries\n",
    "import matplotlib.pyplot as  plt\n",
    "import seaborn as sns\n",
    "\n",
    "# machine learning libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import TargetEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669de298",
   "metadata": {},
   "source": [
    "## Data Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baff0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../data/raw'\n",
    "df_train = pd.read_csv(f'{folder_path}/train.csv', index_col='id')\n",
    "df_test = pd.read_csv(f'{folder_path}/test.csv', index_col='id')\n",
    "df_sample_submission = pd.read_csv(f'{folder_path}/sample_submission.csv',index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf769d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3efc91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_dtypes = {\n",
    "    'Podcast_Name':'category',\n",
    "    'Episode_Title':'category',\n",
    "    'Episode_Length_minutes':'float64',\n",
    "    'Genre':'category',\n",
    "    'Host_Popularity_percentage':'float64',\n",
    "    'Publication_Day':'category',\n",
    "    'Publication_Time':'category',\n",
    "    'Guest_Popularity_percentage':'float64',\n",
    "    'Number_of_Ads':'float64',\n",
    "    'Episode_Sentiment':'object',\n",
    "    'Listening_Time_minutes':'float64',\n",
    "}\n",
    "\n",
    "TARGET_COLUMN = 'Listening_Time_minutes'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe538dc",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc21fc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    \n",
    "    # Parse episode number\n",
    "    df['Episode_Number_categorical'] = (\n",
    "        df\n",
    "            ['Episode_Title']\n",
    "            .str.split(' ') # split based on space so that each element is a list ['Episode','12']\n",
    "            .apply(lambda lst: lst[1])\n",
    "            .astype('category')\n",
    "    )\n",
    "\n",
    "    df = df.drop(columns='Episode_Title')\n",
    "\n",
    "    df['is_weekend']   = df['Publication_Day'].isin(['Saturday', 'Sunday']).astype('float64')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f439d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(X: pd.DataFrame):\n",
    "    \n",
    "    # Drop non-important columns\n",
    "    CAT_COLUMNS = [\"Genre\",\"Publication_Day\",\"Episode_Sentiment\",\"Publication_Time\",\"Podcast_Name\"]\n",
    "    X[CAT_COLUMNS] = X[CAT_COLUMNS].astype('category')\n",
    "\n",
    "    X = feature_engineering(X)\n",
    "\n",
    "    return X # Enabled this to stop warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308af2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_encoding(X_train, y_train, X_test):\n",
    "\n",
    "    ### TARGET ENCODING\n",
    "    #Â Categorical Columns\n",
    "    categorical_columns = [\"Genre\",\"Publication_Day\",\"Episode_Sentiment\",\"Publication_Time\",\"Podcast_Name\"]\n",
    "    categorical_encoded_columns = [column_name + '_TE' for column_name in categorical_columns]\n",
    "\n",
    "    encoder = TargetEncoder(categories='auto', smooth='auto', cv=5, random_state=42)\n",
    "    encoder.fit(X_train[categorical_columns], y_train)\n",
    "    X_train[categorical_encoded_columns] = encoder.transform(X_train[categorical_columns])\n",
    "    X_test[categorical_encoded_columns] = encoder.transform(X_test[categorical_columns])    \n",
    "\n",
    "    # # Interaction Columns\n",
    "    # interaction_features = [\n",
    "    #     ('Publication_Day','Publication_Time')\n",
    "    # ]\n",
    "\n",
    "    # interaction_features_to_be_encoded = []\n",
    "    # for feature_1, feature_2 in interaction_features:\n",
    "    #     feature_name = feature_1 + '_' + feature_2 + '_TE'\n",
    "    #     X_train[feature_name] = (X_train[feature_1].astype('str') + '_' + X_train[feature_2].astype('str')).astype('category')\n",
    "    #     X_test[feature_name] = (X_test[feature_1].astype('str') + '_' + X_test[feature_2].astype('str')).astype('category')\n",
    "    #     interaction_features_to_be_encoded.append(feature_name)\n",
    "    \n",
    "    # encoder = TargetEncoder(categories='auto', smooth='auto', cv=5, random_state=42)\n",
    "    # encoder.fit(X_train[interaction_features_to_be_encoded], y_train)\n",
    "    # X_train[interaction_features_to_be_encoded] = encoder.transform(X_train[interaction_features_to_be_encoded])\n",
    "    # X_test[interaction_features_to_be_encoded] = encoder.transform(X_test[interaction_features_to_be_encoded])    \n",
    "\n",
    "    # # Fitting encoder and transforming data\n",
    "\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff51658",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocessing(X:pd.DataFrame):\n",
    "\n",
    "    columns_to_drop = []\n",
    "\n",
    "    X = X.drop(columns=columns_to_drop)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f759e220",
   "metadata": {},
   "source": [
    "## Model fitting\n",
    "\n",
    "### Train Test Split\n",
    "\n",
    "Splitting data into groupings for model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab862e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_validate, cross_val_score\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "NUMBER_OF_SPLITS = 4\n",
    "    \n",
    "outer_kfold = KFold(n_splits=NUMBER_OF_SPLITS)\n",
    "encoder = TargetEncoder(categories='auto', smooth='auto', cv=5, random_state=42)\n",
    "\n",
    "list_train_rmse = []\n",
    "list_test_rmse = []\n",
    "\n",
    "for fold_number, (infold_training_indices, infold_test_indices) in enumerate(outer_kfold.split(df_train), 1):\n",
    "\n",
    "    # Pre-processing of training data in kfold\n",
    "    X_train = df_train.loc[infold_training_indices,df_train.columns != TARGET_COLUMN]\n",
    "    y_train = df_train.loc[infold_training_indices,TARGET_COLUMN]\n",
    "\n",
    "    X_train = preprocessing(X_train)\n",
    "\n",
    "    # Pre-processing of training data in kfold for in-fold validation\n",
    "    X_test = df_train.loc[infold_test_indices,df_train.columns != TARGET_COLUMN]\n",
    "    y_test = df_train.loc[infold_test_indices,TARGET_COLUMN]\n",
    "    \n",
    "    X_test = preprocessing(X_test)\n",
    "\n",
    "    X_train, X_test = target_encoding(X_train=X_train, X_test=X_test, y_train=y_train)\n",
    "\n",
    "    X_train = postprocessing(X_train)\n",
    "    X_test = postprocessing(X_test)\n",
    "\n",
    "    hyperparameters = {\n",
    "        \"max_depth\": -1,\n",
    "        \"num_leaves\": 1024,\n",
    "        \"colsample_bytree\": 0.7,\n",
    "        \"learning_rate\": 0.03,\n",
    "        \"max_bin\": 1024,\n",
    "        \"verbosity\":0\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMRegressor(\n",
    "        **hyperparameters\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X=X_train,\n",
    "        y=y_train,\n",
    "        eval_set=[(X_test,y_test)],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=25,verbose=False)]\n",
    "    )\n",
    "\n",
    "    y_train_preds = model.predict(X_train)\n",
    "    train_rmse = root_mean_squared_error(y_true=y_train,y_pred=y_train_preds)\n",
    "    list_train_rmse.append(train_rmse)\n",
    "\n",
    "    y_test_preds = model.predict(X_test)\n",
    "    test_rmse = root_mean_squared_error(y_true=y_test,y_pred=y_test_preds)\n",
    "    list_test_rmse.append(test_rmse)\n",
    "\n",
    "    print(f'--- Fold {fold_number} Completed ---')\n",
    "    print('train_rmse, test_rmse - ',train_rmse,test_rmse)\n",
    "\n",
    "print('--- Training_Completed ---')\n",
    "print('The average test cross neg_root_mean_squared_error is ', sum(list_test_rmse)/len(list_test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66506282",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The average cross neg_root_mean_squared_error is ', sum(list_test_rmse)/len(list_test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df8790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on entire dataset\n",
    "X_train = df_train.loc[:,df_train.columns != TARGET_COLUMN]\n",
    "y_train = df_train.loc[:,TARGET_COLUMN]\n",
    "\n",
    "X_train = preprocessing(X_train)\n",
    "\n",
    "# Pre-processing of training data in kfold for in-fold validation\n",
    "X_test = df_test\n",
    "\n",
    "X_test = preprocessing(X_test)\n",
    "\n",
    "X_train, X_test = target_encoding(X_train=X_train, X_test=X_test, y_train=y_train)\n",
    "\n",
    "model = lgb.LGBMRegressor(\n",
    "    **hyperparameters\n",
    ")\n",
    "\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKLIST BEFORE RUNNING\n",
    "# 1. is this a new run (start_run run_id empty) or are you inserting into an old run (start run populated)\n",
    "# 2. Do you know the kaggle leaderboard metric? If not set to 999\n",
    "# 3. Is this a leaderboard model? If not then disable the model logging at the end\n",
    "# This take 2 minutes to run\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "# Set our tracking server uri for logging\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"Kaggle S5E4\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(hyperparameters)\n",
    "\n",
    "    # Log the loss metric\n",
    "    mlflow.log_metric(\"cv_neg_root_mean_squared_error\", sum(list_test_rmse)/len(list_test_rmse))\n",
    "    mlflow.log_metric(\"kaggle leaderboard\", 13.10705)\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(\n",
    "        model_input=X_train,\n",
    "        model_output=y_train,\n",
    "    )\n",
    "\n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=model,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c9d712",
   "metadata": {},
   "source": [
    "# Test Set Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e230e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ff3f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample_submission "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127c00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "date = datetime.datetime.now().date().strftime('%Y-%m-%d')\n",
    "\n",
    "model_type = type(model).__name__\n",
    "\n",
    "comment = 'converted_episode_number_to_a_categorical_variable'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bad6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = df_sample_submission.copy()\n",
    "df_submission['Listening_Time_minutes'] = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f299fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the csv to the submissions folder\n",
    "df_submission.to_csv(f'../submissions/{date}-{model_type}-{comment}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
